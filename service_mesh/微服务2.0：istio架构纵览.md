# 简介
本次演讲分三个部分：

1. 首先将介绍服务网格出现的背景以及它解决了什么问题。
2. 然后重点讲解服务网格的集大成者：istio，具体内容包括istio的概念、设计理念、整体架构以及所涉及到架构组件。
3. 最后会对istio做一个演示以便听众对istio有一个直观的体验。

# 微服务的演进
## 分布式系统的8大谬论
The network is reliable.网络是可靠的
Latency is zero.延迟为0
Bandwidth is infinite.带宽是无限的
The network is secure.网络是安全的
Topology doesn't change.拓扑结构不会改变
There is one administrator.至少有一个管理员
Transport cost is zero.传输无需任何代价
The network is homogeneous.所有的网络都是同质的
https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing

## 微服务治理


## 演进路径
从各种不同功能的组件->综合框架SDK->非侵入的sidecar


## sidecar模式


# 服务网格介绍

# Istio介绍
## 概念
An open platform to connect, manage, and secure microservices

 Connect: Resiliency, discovery, load balancing
 Manage: Traffic control, policy enforcement
 Monitor: Metrics, Logging, Tracing
 Secure: End-to-end Authentication and Authorization

## 关键特性
Intelligent Routing and Load Balancing
Control traffic between services with dynamic
route configuration, conduct A/B tests, release
canaries, and gradually upgrade versions using
red/black deployments

Resilience Across Languages and Platforms
Increase reliability by shielding applications from
flaky networks and cascading failures in adverse
conditions

Fleet-Wide Policy Enforcement
Apply organizational policy to the interaction
between services, ensure access policies are
enforced and resources are fairly distributed
among consumers

In-Depth Telemetry and Reporting
Understand the dependencies between services,
the nature and flow of traffic between them, and
quickly identify issues with distributed tracing

## 设计目标
### 最大化透明度
若想Istio被采纳，应该让运维和开发人员只需付出很少的代价就可以从中受益。为此，Istio将自身自动注入到服务间所有的网络路径中。Istio使用sidecar代理来捕获流量，并且在尽可能的地方自动编程网络层，以路由流量通过这些代理，而无需对已部署的应用程序代码进行任何改动。在Kubernetes中，代理被注入到pod中，通过编写iptable规则来捕获流量。一旦注入sidecar代理到pod中并且修改路由规则，Istio就能够调解所有流量。这个原则也适用于性能。当将Istio应用于部署时，运维人员可以发现，为提供这些功能而增加的资源开销是很小的。所有组件和API在设计时都必须考虑性能和规模。

### 增量
随着运维人员和开发人员越来越依赖Istio提供的功能，系统必然和他们的需求一起成长。虽然我们期望继续自己添加新功能，但是我们预计最大的需求是扩展策略系统，集成其他策略和控制来源，并将网格行为信号传播到其他系统进行分析。策略运行时支持标准扩展机制以便插入到其他服务中。此外，它允许扩展词汇表，以允许基于网格生成的新信号来执行策略。

### 可移植性
使用Istio的生态系统将在很多维度上有差异。Istio必须能够以最少的代价运行在任何云或预置环境中。将基于Istio的服务移植到新环境应该是轻而易举的，而使用Istio将一个服务同时部署到多个环境中也是可行的（例如，在多个云上进行冗余部署）。

### 策略一致性
在服务间的API调用中，策略的应用使得可以对网格间行为进行全面的控制，但对于无需在API级别表达的资源来说，对资源应用策略也同样重要。例如，将配额应用到ML训练任务消耗的CPU数量上，比将配额应用到启动这个工作的调用上更为有用。因此，策略系统作为独特的服务来维护，具有自己的API，而不是将其放到代理/sidecar中，这容许服务根据需要直接与其集成。

## 架构介绍
Istio服务网格逻辑上分为数据面板和控制面板。

数据面板由一组智能代理（Envoy）组成，代理部署为边车，调解和控制微服务之间所有的网络通信。

控制面板负责管理和配置代理来路由流量，以及在运行时执行策略。

# Istio组件
## Initializer
## envoy
>The network should be transparent to applications. When network and application problems do occur it should be easy to determine the source of the problem.

## pilot

### 服务模型

### 配置模型

### 代理控制器

### 服务间的通信

### 与外部的通信


#### 发现服务
pilot提供的三类服务发现：
1.SDS是负责列出一组群集的ip：port对的服务发现
2.CDS是负责列出所有envoy集群的集群发现;
3.RDS是负责列出HTTP路由的路由发现;

## Mixer

### 介绍
Mixer is the central point for policy evaluation and extensibility.
Mixer provides the following core features:
Precondition and quota checking (Check)
Telemetry reporting (Report)
Mixer achieves high extensibility by having a general purpose plug-in model - the plug-ins are known as Adapters.

前提条件检查。允许服务在响应来自服务消费者的传入请求之前验证一些前提条件。前提条件可以包括服务使用者是否被正确认证，是否在服务的白名单上，是否通过ACL检查等等。

配额管理。 使服务能够在分配和释放多个维度上的配额，配额这一简单的资源管理工具可以在服务消费者对有限资源发生争用时，提供相对公平的（竞争手段）。频率控制就是配额的一个实例。

遥测报告。使服务能够上报日志和监控。在未来，它还将启用针对服务运营商以及服务消费者的跟踪和计费流。


### 请求处理

生成补充属性。在Mixer中发生的第一件事是运行一组全局配置的适配器，这些适配器负责引入新的属性。这些属性与来自请求的属性组合，以形成操作的全部属性集合。
决议。评估属性集，以确定应用于请求的有效配置。请参阅此处了解这一阶段的的工作原理。有效的配置确定可用于在后续阶段处理请求的一组切面和描述符。
属性处理。拿到属性总集，然后产生一组适配器参数。这里描述了使用简单的声明来初始化属性处理的过程。
适配器调度。决议阶段建立可用切面的集合，而属性处理阶段创建一组适配器参数。适配器调度阶段调用与每个切面相关联的适配器，并传递这些参数给它们。

### Mixer配置
Mixer is an attribute-processing and routing machine. 
Attributes => Instances => Adapters => (Backends)

### handler
配置好的适配器
有些适配器仅仅是把Mixer和后端连接起来，如：listchecker适配器使用一个列表来检查输入
另一些存在逻辑处理，prometheus适配器使用一种可配置的方式，消费指标并对其进行聚合

### 实例
请求属性到一个模板的映射结果

### 规则
Mixer在每次请求时都会执行这些Rule，Rules确定了何时使用一个特定的模板配置来调用一个Handler

## CA

https://istio.io/blog/2017/0.1-auth.html

## Ingress

# Demo

Sidecar代理注入
将部署规范变更为包含初始化容器（配置iptables）和代理容器。
功能也可以在没有初始化的情况下实现, 例如: 使用istioctl kube-inject 
Initializer可被动态webhook替换

透明地处理集群内服务间、从服务到外部服务之间的入口/出口流量

服务代理
C++语言编写, 高并行, 非阻塞
L3/4网络过滤器
外置L7过滤器
HTTP 2, 包括gRPC
服务发现、健康检查
高级负载均衡
统计、度量、跟踪
通过xDS动态配置

运行时的代理配置

流量管理核心组件
管理配置所有的服务代理 
  路由规则
  配置失败恢复特性(超时、重试、断路器)
所有服务网格的典型模型
  Mesos, Consul, CF, Eureka... 

强制实施ACL，速率限制，配额，身份验证，请求跟踪和遥测收集
应用程序和后端设施的中间层（访问控制系统，遥测捕获系统，配额执行系统，计费系统）
先决条件检查
	- 白名单, ACL检测
配额管理
遥测报告

管理外部对服务的访问，是istio的代理。

实现Kubernetes Ingress控制器
配置为一个负载均衡
由Pilot控制
支持路由规则

限制：
忽略注释：
	kubernetes.io/ingress.class: istio
不支持路径上的正则表达式
不支持错误注入



## 参考资料：
1. 对比：https://abhishek-tiwari.com/a-sidecar-for-your-service-mesh/
2. 数据面板&控制面板：http://www.servicemesh.cn/?/article/24


linkerd的内存和CPU要求明显高于Envoy的。与Envoy相比，linkerd提供了极简配置语言，并且明确地不支持热重启，而是依赖于动态配置和服务抽象。linkerd支持HTTP/1.1，Thrift，ThriftMux，HTTP/2（试验阶段）和gRPC（试验阶段）。

### 健康检查
主动健康检查
定期发送请求（例如，对/healthcheck端点的HTTP请求）到后端，并用它来衡量健康状况。
支持三种不同类型的健康检查：
HTTP：HTTP健康检查期间，Envoy将向上游主机发送HTTP请求
L3/L4：在L3/L4健康检查期间，Envoy会向上游主机发送一个可配置的报文
Redis：Envoy将发送一个Redis PING命令，并期待一个PONG响应

通过缓存：在这种模式下，Envoy会将健康检查请求传递给本地服务，但是会将结果缓存一段时间。随后在缓存有效时间内，进行的健康检查都会从缓存获取结果。

被动健康检查
通过检测主数据流中的异常值，来进行被动健康检查。
例如，如果连续出现三个连接错误，则L4负载均衡器会认为后端是不健康的。如果一行中有三个HTTP 503响应代码，则L7负载均衡器会认为后端是不健康的。

### http2：
二进制分帧：HTTP/2 采用二进制格式传输数据，而非 HTTP/1.x 的文本格式。
头部压缩：HTTP/2 对消息头采用 HPACK 进行压缩传输，能够节省消息头占用的网络的流量。而 HTTP/1.x 每次请求，都会携带大量冗余头信息，浪费了很多带宽资源。头压缩能够很好的解决该问题。 
多路复用：直白的说就是所有的请求都是通过一个 TCP 连接并发完成。
Server Push：服务端能够更快的把资源推送给客户端。例如服务端可以主动把 JS 和 CSS 文件推送给客户端，而不需要客户端解析 HTML 再发送这些请求。当客户端需要的时候，它已经在客户端了。

### k8s
支持
跨多个后端pods的简单L4 (TCP/UDP)负载均衡 
1.随机
2.轮训

外部流量的L7负载均衡

不支持：
内部流量的L7负载均衡
限流
智能路由
	流量拆分
	容错
	故障注入
L7 Ingress控制器实现

### 负载均衡模式
随机
选择一个随机的健康主机
轮训
每个健康的上游主机按循环顺序选择。
权重最小请求
请求最少的负载均衡器使用O(1)算法来选择两个随机的健康主机，并选择活跃请求较少的主机。


### 服务治理的目标：
防止业务服务架构腐化
快速故障定界定位
服务微管控
服务生命周期管理

### 通信安全
服务与Envoy之间的本地TCP连接
代理之间的双向TLS连接
安全命名：在握手过程中，客户端Envoy检查服务器端证书提供的服务帐号是否允许运行目标服务

### 密钥管理
为每个service account生成一个 SPIFFE 密钥和证书对
根据service account将密钥和证书对分发给每个pod
定期轮换密钥和证书
必要时撤销特定的密钥和证书对

### 部署阶段(Kubernetes场景)
1. Istio CA观察Kubernetes API Server，为每个现有和新的service account创建一个
SPIFFE 密钥和证书对，并将其发送到API服务器。
2. 当创建pod时，API Server会根据service account使用Kubernetes secrets 来挂载密钥和
证书对。
3. Pilot 使用适当的密钥和证书以及安全命名信息生成配置，该信息定义了什么服务帐户可
以运行某个服务，并将其传递给Envoy。

### 运行时阶段
1. 来自客户端服务的出站流量被重新路由到它本地的Envoy。
2. 客户端Envoy与服务器端Envoy开始相互TLS握手。在握手期间，它还进行安全的命名检
查，以验证服务器证书中显示的服务帐户是否可以运行服务器服务。
3. mTLS连接建立后，流量将转发到服务器端Envoy，然后通过本地TCP连接转发到服务器服务。

### 监听器
服务（程序）监听者，就是真正干活的工作线程。envoy会暴露一个或者多个监听器监听服务请求方。监听器可以有多个filter，根据filter链对这些请求做出处理。
